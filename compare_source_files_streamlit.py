# -*- coding: utf-8 -*-
"""
Streamlitåº”ç”¨ï¼Œç”¨äºæ¯”è¾ƒå¤šä¸ªExcelæ–‡ä»¶å¹¶ç”Ÿæˆå·®å¼‚æŠ¥å‘Šã€‚
"""

import streamlit as st
import pandas as pd
import os
import glob
import json
import time
from http import HTTPStatus
import dashscope
from datetime import datetime
import logging
# from tkinter import Tk, filedialog # ç§»é™¤ tkinter å¯¼å…¥
from itertools import combinations # ç”¨äºç”Ÿæˆæ–‡ä»¶å¯¹
from io import BytesIO # å¯¼å…¥BytesIO

# --- Kimi API ç›¸å…³å‡½æ•° (ä» compare_source_files.py è¿ç§») ---

def get_comparison_from_kimi(file1_content, file2_content, file1_name, file2_name, sheet_name, api_key, retries=3, delay=5):
    """
    ä½¿ç”¨Moonshot-Kimiæ¨¡å‹æ¥æ¯”è¾ƒä¸¤ä¸ªDataFrameçš„å†…å®¹å¹¶ç”Ÿæˆæ€»ç»“ã€‚
    """
    model_name = "Moonshot-Kimi-K2-Instruct"
    prompt = f"""
# è§’è‰²
ä½ æ˜¯ä¸€ä½ç²¾é€šæ•°æ®æ¯”å¯¹çš„æ•°æ®åˆ†æä¸“å®¶ã€‚

# èƒŒæ™¯
æˆ‘éœ€è¦æ¯”è¾ƒä¸¤ä¸ªExcelæ–‡ä»¶ï¼ˆ`{file1_name}` å’Œ `{file2_name}`ï¼‰ä¸­ï¼Œåä¸º '{sheet_name}' çš„å·¥ä½œè¡¨ã€‚ä½ éœ€è¦å¸®æˆ‘ç²¾ç¡®åœ°è¯†åˆ«å¹¶æ€»ç»“è¿™ä¸¤ä¸ªæ•°æ®ç‰ˆæœ¬ä¹‹é—´çš„æ‰€æœ‰å·®å¼‚ã€‚

# ä»»åŠ¡
ä½ çš„ä»»åŠ¡æ˜¯æ·±å…¥ã€ç»†è‡´åœ°æ¯”è¾ƒä»¥ä¸‹ä¸¤ä¸ªJSONæ ¼å¼çš„æ•°æ®å†…å®¹ï¼Œå®ƒä»¬åˆ†åˆ«æ¥è‡ªä¸¤ä¸ªExcelæ–‡ä»¶çš„ '{sheet_name}' å·¥ä½œè¡¨ã€‚ç„¶åï¼Œä»¥ä¸€ä¸ªæ¸…æ™°ã€ç»“æ„åŒ–çš„Markdownè¡¨æ ¼å½¢å¼ï¼Œæ€»ç»“å‡ºæ‰€æœ‰çš„ä¸åŒä¹‹å¤„ã€‚

# è¾“å…¥æ•°æ®
## æ–‡ä»¶1: `{file1_name}` (å·¥ä½œè¡¨: {sheet_name})
```json
{file1_content}
```

## æ–‡ä»¶2: `{file2_name}` (å·¥ä½œè¡¨: {sheet_name})
```json
{file2_content}
```

# è¾“å‡ºè¦æ±‚
1.  **è¿›è¡Œæ€è€ƒ** (ä½†ä¸è¦åœ¨æœ€ç»ˆè¾“å‡ºä¸­æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹):
    *   é¦–å…ˆï¼Œé€šè§ˆä¸¤ä¸ªæ•°æ®é›†ï¼Œç†è§£å…¶æ•´ä½“ç»“æ„ã€‚
    *   é€é¡¹å¯¹æ¯”ï¼Œæ‰¾å‡ºæ‰€æœ‰å·®å¼‚ã€‚å·®å¼‚å¯èƒ½åŒ…æ‹¬ä½†ä¸é™äºï¼š
        *   **æ•°å€¼æˆ–æ–‡æœ¬ä¸åŒ**: åŒä¸€ä½ç½®çš„å•å…ƒæ ¼å†…å®¹ä¸ä¸€è‡´ã€‚
        *   **å­˜åœ¨æ€§å·®å¼‚**: æŸå¤„åœ¨ä¸€ä¸ªæ–‡ä»¶ä¸­æœ‰æ•°æ®ï¼Œåœ¨å¦ä¸€ä¸ªæ–‡ä»¶ä¸­ä¸ºç©ºã€‚
        *   **æ ¼å¼ä¸åŒ**: å†…å®¹ç›¸ä¼¼ä½†è¡¨è¾¾æ–¹å¼æˆ–æ ¼å¼æœ‰åˆ«ï¼ˆä¾‹å¦‚ï¼Œâ€œN/Aâ€ vs â€œ-â€, â€œ1,000â€ vs â€œ1000â€ï¼‰ã€‚
        *   **è¡Œæˆ–åˆ—çš„å¢åˆ **: ä¸€ä¸ªæ–‡ä»¶å¯èƒ½æ¯”å¦ä¸€ä¸ªæ–‡ä»¶å¤šæˆ–å°‘å‡ è¡Œæˆ–å‡ åˆ—æ•°æ®ã€‚
        *   **é€»è¾‘å·®å¼‚**: ä¾‹å¦‚ï¼Œä¸€ä¸ªæ–‡ä»¶æ ‡è®°ä¸ºâ€œä¸é€‚ç”¨â€ï¼Œå¦ä¸€ä¸ªæ–‡ä»¶å´æœ‰å…·ä½“æ•°å€¼ã€‚

2.  **æ ¼å¼åŒ–è¾“å‡º**:
    *   ä½  **å¿…é¡»** ä»¥ä¸€ä¸ªMarkdownè¡¨æ ¼æ¥å‘ˆç°æ¯”è¾ƒç»“æœã€‚
    *   è¡¨æ ¼çš„ **è¡¨å¤´å¿…é¡»æ˜¯**ï¼š`| é¡¹ç›® | æ–‡ä»¶1ï¼š{file1_name} | æ–‡ä»¶2ï¼š{file2_name} | å·®å¼‚è¯´æ˜ |`
    *   åœ¨â€œé¡¹ç›®â€åˆ—ä¸­ï¼Œæ¸…æ™°åœ°æè¿°å·®å¼‚æ‰€åœ¨çš„è¡Œã€åˆ—æˆ–å­—æ®µã€‚
    *   åœ¨â€œå·®å¼‚è¯´æ˜â€åˆ—ä¸­ï¼Œç®€è¦è§£é‡Šå·®å¼‚çš„ç±»å‹ï¼ˆä¾‹å¦‚ï¼Œâ€œæ•°å€¼ä¸åŒâ€ã€â€œæ ¼å¼ä¸ä¸€è‡´â€ã€â€œè¡Œè¢«ç§»é™¤â€ç­‰ï¼‰ã€‚
    *   **å¦‚æœä¸¤ä¸ªæ–‡ä»¶çš„å·¥ä½œè¡¨å†…å®¹å®Œå…¨æ²¡æœ‰å·®å¼‚**ï¼Œè¯·è¿”å›ä¸€ä¸ªä»…åŒ…å«è¡¨å¤´çš„ç©ºMarkdownè¡¨æ ¼ã€‚
    *   **ä¸è¦è¾“å‡ºä»»ä½•** è¡¨æ ¼ä¹‹å¤–çš„æ–‡å­—ã€è§£é‡Šã€æ€»ç»“ã€æ ‡é¢˜æˆ–ä»£ç å—æ ‡è®°ã€‚ä½ çš„è¾“å‡ºå¿…é¡»ä» `| é¡¹ç›® |` å¼€å§‹ã€‚

# ç¤ºä¾‹è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼ã€‚

| é¡¹ç›® | æ–‡ä»¶1ï¼šReport_v2.xlsx | æ–‡ä»¶2ï¼šReport_v1.xlsx | å·®å¼‚è¯´æ˜ |
|---|---|---|---|
| **ç¬¬3è¡Œ, 'é”€å”®é¢'åˆ—** | 15,000 | 12,500 | æ•°å€¼ä¸åŒ |
| **ç¬¬5è¡Œ** | (æ­¤è¡Œä¸ºæ–°å¢) | (æ­¤è¡Œä¸å­˜åœ¨) | æ–‡ä»¶1æ–°å¢äº†ä¸€è¡Œæ•°æ® |
| **'å¤‡æ³¨'åˆ—** | æ‰€æœ‰å¤‡æ³¨å‡ä¸ºå¤§å†™ | æ‰€æœ‰å¤‡æ³¨å‡ä¸ºå°å†™ | æ–‡æœ¬æ ¼å¼ä¸åŒ |
"""
    messages = [{'role': 'user', 'content': prompt}]

    for attempt in range(retries):
        try:
            response = dashscope.Generation.call(
                model=model_name,
                messages=messages,
                api_key=api_key,
                result_format='message'
            )

            if response.status_code == HTTPStatus.OK:
                content = response.output.choices[0].message.content
                logging.info(f"Kimiå¯¹å·¥ä½œè¡¨ '{sheet_name}' åˆ†ææˆåŠŸ (å°è¯• {attempt + 1}/{retries})ã€‚")
                return content
            else:
                error_msg = (f"Kimi API è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{retries}) for sheet '{sheet_name}'. "
                             f"çŠ¶æ€ç : {response.status_code}, é”™è¯¯ç : {response.code}, é”™è¯¯ä¿¡æ¯: {response.message}")
                logging.error(error_msg)

        except Exception as e:
            error_msg = f"è°ƒç”¨Kimi APIæ—¶å‘ç”Ÿå¼‚å¸¸ (å°è¯• {attempt + 1}/{retries}) for sheet '{sheet_name}': {str(e)}"
            logging.error(error_msg)

        if attempt < retries - 1:
            logging.warning(f"å°†åœ¨ {delay} ç§’åé‡è¯•...")
            time.sleep(delay)

    logging.error(f"æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œæ— æ³•è·å–å·¥ä½œè¡¨ '{sheet_name}' çš„æ¯”è¾ƒç»“æœã€‚")
    return None


def convert_df_to_json_string(df, orient='records', indent=4):
    """å°†DataFrameè½¬æ¢ä¸ºæ ¼å¼åŒ–çš„JSONå­—ç¬¦ä¸²ç”¨äºPromptã€‚"""
    return df.to_json(orient=orient, indent=indent, force_ascii=False)

# --- Streamlit UI é…ç½® ---
st.set_page_config(page_title="Excel æ–‡ä»¶å¯¹æ¯”å·¥å…·", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š Excel æ–‡ä»¶å¯¹æ¯”å·¥å…·")

# --- æ—¥å¿—é…ç½® ---
log_expander = st.expander("æŸ¥çœ‹æ—¥å¿—", expanded=False)
log_container = log_expander.container()

class StreamlitLogHandler(logging.Handler):
    """å°†æ—¥å¿—è®°å½•å‘é€åˆ°Streamlit UIå®¹å™¨çš„æ—¥å¿—å¤„ç†å™¨ã€‚"""
    def __init__(self, container):
        super().__init__()
        self.container = container

    def emit(self, record):
        """æ ¼å¼åŒ–å¹¶æ˜¾ç¤ºæ—¥å¿—è®°å½•ã€‚"""
        msg = self.format(record)
        level = record.levelno
        if level >= logging.ERROR:
            self.container.error(msg)
        elif level >= logging.WARNING:
            self.container.warning(msg)
        else:
            self.container.info(msg)

def setup_logging(container):
    """é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨ä»¥å°†æ—¥å¿—é‡å®šå‘åˆ°Streamlit UIã€‚"""
    logger = logging.getLogger()
    if not any(isinstance(h, StreamlitLogHandler) for h in logger.handlers):
        logger.setLevel(logging.INFO)
        handler = StreamlitLogHandler(container)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', '%H:%M:%S')
        handler.setFormatter(formatter)
        logger.addHandler(handler)

# --- æ–‡ä»¶ä¸Šä¼ ç»„ä»¶ ---
def handle_file_upload():
    """å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶ï¼Œå¹¶è¿”å›æ–‡ä»¶åˆ—è¡¨ã€‚"""
    uploaded_files = st.file_uploader("è¯·ä¸Šä¼ è¦å¯¹æ¯”çš„ Excel æ–‡ä»¶ (.xlsx)", type=["xlsx"], accept_multiple_files=True)
    
    if uploaded_files:
        # å°†ä¸Šä¼ çš„æ–‡ä»¶ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•ï¼Œä»¥ä¾¿åç»­å¤„ç†
        # æ³¨æ„ï¼šåœ¨ Streamlit Cloud ä¸­ï¼Œæ–‡ä»¶ä¸Šä¼ æ˜¯ä¸´æ—¶çš„ï¼Œé€šå¸¸ä¿å­˜åœ¨å†…å­˜æˆ–ä¸´æ—¶å­˜å‚¨ä¸­
        # è¿™é‡Œæˆ‘ä»¬ç›´æ¥å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡
        return uploaded_files
    return []

# --- åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ ---
if 'uploaded_files' not in st.session_state:
    st.session_state['uploaded_files'] = []
if 'output_dir' not in st.session_state:
    st.session_state['output_dir'] = ""
if 'api_key' not in st.session_state:
    st.session_state['api_key'] = ""
if 'comparison_results' not in st.session_state:
    st.session_state['comparison_results'] = None
if 'final_excel_path' not in st.session_state:
    st.session_state['final_excel_path'] = None

# --- ä¾§è¾¹æ é…ç½® ---
with st.sidebar:
    st.header("âš™ï¸ é…ç½®é€‰é¡¹")

    # 1. æ–‡ä»¶ä¸Šä¼ 
    st.subheader("1. ä¸Šä¼ æ–‡ä»¶")
    uploaded_files = handle_file_upload()
    st.session_state['uploaded_files'] = uploaded_files # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ—è¡¨

    st.divider()

    # 2. APIå¯†é’¥è¾“å…¥
    st.subheader("2. è¾“å…¥å¯†é’¥")
    st.text_input("Kimi API å¯†é’¥", type="password", key='api_key', placeholder="è¯·è¾“å…¥æ‚¨çš„DashScope APIå¯†é’¥", help="æ­¤å·¥å…·éœ€è¦è°ƒç”¨Kimiæ¨¡å‹è¿›è¡ŒAIåˆ†æã€‚")

    st.divider()

    st.subheader("æ“ä½œ")
    process_button = st.button("å¼€å§‹å¯¹æ¯”åˆ†æ", type="primary", use_container_width=True)

# --- æ–‡ä»¶æ¯”è¾ƒæ ¸å¿ƒé€»è¾‘ ---
def perform_comparison(uploaded_files, api_key):
    """
    å¤„ç†ä¸Šä¼ çš„Excelæ–‡ä»¶ï¼Œè¿›è¡Œä¸¤ä¸¤æ¯”è¾ƒï¼Œå¹¶å°†æ‰€æœ‰ç»“æœæ•´åˆåˆ°ä¸€ä¸ªExcelæ–‡ä»¶çš„å†…å­˜å¯¹è±¡ä¸­ã€‚
    è¿”å›ä¸€ä¸ªåŒ…å«Excelæ–‡ä»¶æ•°æ®çš„BytesIOå¯¹è±¡ã€‚
    """
    if len(uploaded_files) < 2:
        logging.error("è¯·ä¸Šä¼ è‡³å°‘ä¸¤ä¸ª Excel æ–‡ä»¶è¿›è¡Œæ¯”è¾ƒã€‚")
        return None

    file_data = [{'name': f.name, 'file_obj': f} for f in uploaded_files]
    file_pairs = list(combinations(file_data, 2))
    logging.info(f"å‘ç° {len(file_data)} ä¸ª Excel æ–‡ä»¶ï¼Œå°†è¿›è¡Œ {len(file_pairs)} å¯¹ä¸¤ä¸¤æ¯”è¾ƒã€‚")

    # åˆ›å»ºä¸€ä¸ªå†…å­˜ä¸­çš„Excelå†™å…¥å™¨
    output_buffer = BytesIO()
    with pd.ExcelWriter(output_buffer, engine='xlsxwriter') as writer:
        overview_data = [] # ç”¨äºæ€»è§ˆè¡¨çš„æ•°æ®

        for i, (file1_info, file2_info) in enumerate(file_pairs):
            file1_name, file2_name = file1_info['name'], file2_info['name']
            file1_obj, file2_obj = file1_info['file_obj'], file2_info['file_obj']
            
            # åˆ›å»ºä¸€ä¸ªå¯¹ç”¨æˆ·å‹å¥½çš„å·¥ä½œè¡¨åç§°
            pair_sheet_name_base = f"{file1_name[:10]}_vs_{file2_name[:10]}"
            
            logging.info(f"\n--- å¼€å§‹æ¯”è¾ƒå¯¹ {i+1}/{len(file_pairs)}: {file1_name} vs {file2_name} ---")

            try:
                # é‡ç½®æ–‡ä»¶å¯¹è±¡çš„è¯»å–æŒ‡é’ˆå¹¶ä½¿ç”¨ ExcelFile ä¼˜åŒ–å†…å­˜
                file1_obj.seek(0)
                file2_obj.seek(0)
                xls1 = pd.ExcelFile(file1_obj)
                xls2 = pd.ExcelFile(file2_obj)
                sheets1, sheets2 = set(xls1.sheet_names), set(xls2.sheet_names)

            except Exception as e:
                logging.error(f"æ‰“å¼€ Excel æ–‡ä»¶ '{file1_name}' æˆ– '{file2_name}' æ—¶å‡ºé”™: {e}")
                overview_data.append({'æ–‡ä»¶1': file1_name, 'æ–‡ä»¶2': file2_name, 'çŠ¶æ€': 'æ‰“å¼€é”™è¯¯', 'è¯´æ˜': str(e)})
                continue

            common_sheets = sorted(list(sheets1.intersection(sheets2)))
            
            # ä¸ºæ¯ä¸ªæ–‡ä»¶å¯¹åˆ›å»ºä¸€ä¸ªæ¦‚è§ˆå·¥ä½œè¡¨
            pair_overview_data = {
                'çŠ¶æ€': ['å…±æœ‰å·¥ä½œè¡¨', 'ä»…åœ¨æ–‡ä»¶1ä¸­', 'ä»…åœ¨æ–‡ä»¶2ä¸­'],
                'å·¥ä½œè¡¨åç§°': [", ".join(common_sheets), ", ".join(sorted(list(sheets1 - sheets2))), ", ".join(sorted(list(sheets2 - sheets1)))]
            }
            pair_overview_df = pd.DataFrame(pair_overview_data)
            pair_overview_df.to_excel(writer, sheet_name=f"æ¦‚è§ˆ_{pair_sheet_name_base[:20]}", index=False)

            if not common_sheets:
                logging.warning(f"æ–‡ä»¶ '{file1_name}' å’Œ '{file2_name}' æ²¡æœ‰å…±åŒçš„å·¥ä½œè¡¨å¯ä¾›æ¯”è¾ƒã€‚")
                overview_data.append({'æ–‡ä»¶1': file1_name, 'æ–‡ä»¶2': file2_name, 'çŠ¶æ€': 'æ— å…±åŒå·¥ä½œè¡¨', 'è¯´æ˜': 'æ— å…±åŒå·¥ä½œè¡¨ï¼Œè·³è¿‡ã€‚'})
                continue

            logging.info(f"å°†æ¯”è¾ƒå…±åŒçš„å·¥ä½œè¡¨: {', '.join(common_sheets)}")

            for sheet_name in common_sheets:
                logging.info(f"--- æ­£åœ¨å¤„ç†å·¥ä½œè¡¨: {sheet_name} ---")
                try:
                    logging.info(f"æ­£åœ¨ä» '{file1_name}' è¯»å–å·¥ä½œè¡¨ '{sheet_name}'...")
                    current_df1 = pd.read_excel(xls1, sheet_name=sheet_name)
                    logging.info(f"æ­£åœ¨ä» '{file2_name}' è¯»å–å·¥ä½œè¡¨ '{sheet_name}'...")
                    current_df2 = pd.read_excel(xls2, sheet_name=sheet_name)
                except Exception as e:
                    logging.error(f"è¯»å–å·¥ä½œè¡¨ '{sheet_name}' æ—¶å‡ºé”™: {e}")
                    pd.DataFrame({'é”™è¯¯': [f"è¯»å–å·¥ä½œè¡¨ '{sheet_name}' æ—¶å‡ºé”™: {e}"]}).to_excel(writer, sheet_name=f"é”™è¯¯_{pair_sheet_name_base[:20]}", index=False)
                    continue

                # å®šä¹‰å½“å‰æ¯”è¾ƒçš„è¯¦ç»†å·¥ä½œè¡¨åç§°
                details_sheet_name = f"å·®å¼‚_{pair_sheet_name_base[:15]}_{sheet_name[:10]}"

                if current_df1.equals(current_df2):
                    logging.info(f"å·¥ä½œè¡¨ '{sheet_name}' å†…å®¹å®Œå…¨ç›¸åŒï¼Œè·³è¿‡APIåˆ†æã€‚")
                    details_df = pd.DataFrame([{'çŠ¶æ€': 'å†…å®¹å®Œå…¨ç›¸åŒ', 'è¯´æ˜': f"å·¥ä½œè¡¨ '{sheet_name}' åœ¨ä¸¤ä¸ªæ–‡ä»¶ä¸­çš„å†…å®¹å®Œå…¨ç›¸åŒã€‚"}])
                    details_df.to_excel(writer, sheet_name=details_sheet_name, index=False)
                    continue
                
                logging.info(f"å·¥ä½œè¡¨ '{sheet_name}' å†…å®¹å­˜åœ¨å·®å¼‚ï¼Œå‡†å¤‡è°ƒç”¨ Kimi API è¿›è¡Œåˆ†æã€‚")
                comparison_result = get_comparison_from_kimi(
                    convert_df_to_json_string(current_df1),
                    convert_df_to_json_string(current_df2),
                    file1_name, file2_name, sheet_name, api_key
                )

                if comparison_result:
                    try:
                        table_str = comparison_result.strip()
                        lines = table_str.strip().split('\n')
                        if len(lines) > 1 and '|' in lines[0] and '---' in lines[1]:
                            header = [h.strip() for h in lines[0].strip().strip('|').split('|')]
                            data_rows = [ [p.strip() for p in line.strip().strip('|').split('|')] for line in lines[2:] if '|' in line]
                            details_df = pd.DataFrame(data_rows, columns=header)
                            if details_df.empty:
                                details_df.loc[0] = ["æ— ç¨‹åºåŒ–å·®å¼‚"] * len(header)
                                details_df.iloc[0, -1] = "KimiæŠ¥å‘Šäº†ä¸€ä¸ªç©ºè¡¨æ ¼ï¼Œå¯èƒ½æ„å‘³ç€å†…å®¹è™½ä¸åŒä½†æ— æ˜¾è‘—ç»“æ„æ€§å·®å¼‚ã€‚"
                        else:
                             details_df = pd.DataFrame([{'è¯´æ˜': f"KimiæŠ¥å‘Šåœ¨ '{sheet_name}' ä¸­æœªå‘ç°ç»“æ„åŒ–å·®å¼‚ã€‚", 'åŸå§‹è¾“å‡º': table_str}])
                        
                        details_df.to_excel(writer, sheet_name=details_sheet_name, index=False)
                        
                        # è‡ªåŠ¨è°ƒæ•´åˆ—å®½
                        worksheet = writer.sheets[details_sheet_name]
                        for idx, col in enumerate(details_df):
                            series = details_df[col]
                            max_len = max((series.astype(str).map(len).max(), len(str(series.name)))) + 2
                            worksheet.set_column(idx, idx, min(max_len, 50))

                        logging.info(f"å·²å°† '{sheet_name}' çš„è¯¦ç»†å·®å¼‚å¯¹æ¯”ç»“æœå†™å…¥åˆ°æ€»æŠ¥å‘Šä¸­ã€‚")
                    except Exception as e:
                        logging.error(f"è§£æKimiä¸ºå·¥ä½œè¡¨ '{sheet_name}' è¿”å›çš„Markdownè¡¨æ ¼å¹¶ä¿å­˜æ—¶å‡ºé”™: {e}")
                        pd.DataFrame({'åŸå§‹è¿”å›å†…å®¹': [comparison_result]}).to_excel(writer, sheet_name=f"é”™è¯¯_{pair_sheet_name_base[:20]}", index=False)
                else:
                    logging.warning(f"æœªèƒ½ä»Kimiè·å–å·¥ä½œè¡¨ '{sheet_name}' çš„æ¯”è¾ƒç»“æœã€‚")
                    pd.DataFrame({'é”™è¯¯': [f"æœªèƒ½ä»Kimiè·å– '{sheet_name}' çš„å·¥ä½œæµæ¯”è¾ƒç»“æœã€‚"]}).to_excel(writer, sheet_name=f"é”™è¯¯_{pair_sheet_name_base[:20]}", index=False)
            
            overview_data.append({'æ–‡ä»¶1': file1_name, 'æ–‡ä»¶2': file2_name, 'çŠ¶æ€': 'å·²å®Œæˆ', 'è¯´æ˜': f"è¯¦ç»†æ¯”è¾ƒç»“æœå·²ç”Ÿæˆåœ¨ExcelæŠ¥å‘Šä¸­ã€‚"})
            logging.info(f"--- æ¯”è¾ƒå¯¹ {file1_name} vs {file2_name} å®Œæˆ ---")

        # æœ€åå†™å…¥æ€»è§ˆè¡¨
        overall_overview_df = pd.DataFrame(overview_data)
        overall_overview_df.to_excel(writer, sheet_name='æ€»è§ˆ-æ‰€æœ‰æ¯”è¾ƒå¯¹', index=False)
        worksheet = writer.sheets['æ€»è§ˆ-æ‰€æœ‰æ¯”è¾ƒå¯¹']
        for idx, col in enumerate(overall_overview_df):
            series = overall_overview_df[col]
            max_len = max((series.astype(str).map(len).max(), len(str(series.name)))) + 2
            worksheet.set_column(idx, idx, min(max_len, 60))
            
        logging.info("å·²ç”Ÿæˆæ€»çš„æ¦‚è§ˆè¡¨ã€‚")

    logging.info("\næ‰€æœ‰æ¯”è¾ƒå®Œæˆï¼å‡†å¤‡æä¾›ä¸‹è½½ã€‚")
    output_buffer.seek(0)
    return output_buffer


# --- ä¸»ç•Œé¢ ---
setup_logging(log_container) # é…ç½®æ—¥å¿—å¤„ç†å™¨

if process_button:
    log_container.empty()
    st.session_state['comparison_results'] = None
    st.session_state['final_excel_path'] = None

    uploaded_files = st.session_state.get('uploaded_files', [])
    api_key = st.session_state.get('api_key')

    if not uploaded_files or len(uploaded_files) < 2:
        st.error("âŒ è¯·å…ˆä¸Šä¼ è‡³å°‘ä¸¤ä¸ª Excel æ–‡ä»¶ã€‚")
    elif not api_key or "sk-" not in api_key:
        st.error("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„ Kimi API å¯†é’¥ã€‚")
    else:
        dashscope.api_key = api_key
        logging.info("APIå¯†é’¥å·²è®¾ç½®ã€‚å¼€å§‹æ‰§è¡Œæ¯”è¾ƒ...")

        with st.spinner("ğŸ¤– AIæ­£åœ¨è¿›è¡Œæ–‡ä»¶ä¸¤ä¸¤å¯¹æ¯”åˆ†æï¼Œè¯·ç¨å€™..."):
            final_report_buffer = perform_comparison(uploaded_files, api_key)

        if final_report_buffer:
            st.success("âœ… å¯¹æ¯”åˆ†æå®Œæˆï¼è¯·ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ä¸‹è½½æ€»æŠ¥å‘Šã€‚")
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            final_filename = f"Overall_Comparison_{timestamp}.xlsx"
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½æ€»æŠ¥å‘Š (Excel)",
                data=final_report_buffer,
                file_name=final_filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        else:
            st.error("âš ï¸ æ–‡ä»¶å¯¹æ¯”åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥ä¸Šæ–¹æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯ã€‚")

else:
    st.info("ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ï¼è¯·åœ¨å·¦ä¾§ä¸Šä¼  Excel æ–‡ä»¶ï¼Œè¾“å…¥ API å¯†é’¥ï¼Œç„¶åç‚¹å‡»â€œå¼€å§‹å¯¹æ¯”åˆ†æâ€ã€‚")
